# University Dropout Prediction

A comprehensive machine learning project for predicting university student dropout risk using academic, administrative, and socioeconomic data.

## ğŸ“Š Project Overview

This project implements a binary classification system to predict student dropout risk using multiple machine learning algorithms. The study compares base models with their optimized versions and identifies the most effective approaches for early intervention.

## ğŸ” Key Findings

- **Best Performing Models**: Random Forest (base) and Balanced Random Forest Classifier
- **Unexpected Result**: Base models outperformed Grid Search optimized versions
- **Algorithms Evaluated**: Random Forest, XGBoost, SVM, Balanced Random Forest
- **Techniques Used**: SMOTE for class balancing, SHAP for model interpretability

## ğŸ“ Project Structure

```
university-dropout-prediction/
â”‚
â”œâ”€â”€ notebooks/                     # Jupyter notebooks (main workflow)
â”‚   â”œâ”€â”€ 01_data_preparation.ipynb         # Target variable creation
â”‚   â”œâ”€â”€ 02_exploratory_data_analysis.ipynb # Descriptive analysis
â”‚   â”œâ”€â”€ 03_data_analysis.ipynb            # Data analysis
â”‚   â”œâ”€â”€ 04_data_imputation.ipynb          # Missing data handling
â”‚   â”œâ”€â”€ 05_feature_encoding_analysis.ipynb # Encoding analysis
â”‚   â”œâ”€â”€ 06_feature_encoding.ipynb         # Variable encoding
â”‚   â”œâ”€â”€ 07_model_training_smote.ipynb     # Main model training
â”‚   â”œâ”€â”€ 08_balanced_random_forest.ipynb   # Balanced RF analysis
â”‚   â””â”€â”€ archive/                          # Backup notebooks
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                       # Original datasets
â”‚   â””â”€â”€ processed/                 # Processed datasets
â”‚       â””â”€â”€ df_objetivo/           # Target variable datasets
â”‚
â”œâ”€â”€ src/                          # Source code
â”‚   â””â”€â”€ shap_utils.py             # SHAP utilities for interpretability
â”‚
â”œâ”€â”€ models/                       # Trained models (to be added)
â”œâ”€â”€ results/                      # Results and visualizations
â”œâ”€â”€ docs/                         # Additional documentation
â”‚
â”œâ”€â”€ requirements.txt              # Project dependencies
â”œâ”€â”€ .gitignore                   # Git ignore file
â””â”€â”€ README.md                    # This file
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- Jupyter Notebook or JupyterLab

### Installation

1. Clone the repository:
```bash
git clone https://github.com/acperaltaf/university-dropout-prediction.git
cd university-dropout-prediction
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Launch Jupyter:
```bash
jupyter notebook
```

4. Run notebooks in sequence (01 â†’ 02 â†’ ... â†’ 08)

## ğŸ“‹ Methodology

### 1. Data Preparation
- **Target Variable Creation**: Risk threshold defined using 80th percentile of academic delay
- **Feature Engineering**: Academic progress indicators and socioeconomic variables

### 2. Exploratory Data Analysis
- Statistical analysis of student academic patterns
- Correlation analysis between variables
- Distribution analysis of risk factors

### 3. Data Preprocessing
- **Missing Data**: Systematic imputation strategy
- **Feature Encoding**: Categorical variable transformation
- **Scaling**: Standardization of numerical features
- **Class Balancing**: SMOTE technique for imbalanced datasets

### 4. Model Development
- **Base Models**: Random Forest, XGBoost, SVM, Balanced Random Forest
- **Optimization**: Grid Search hyperparameter tuning
- **Evaluation**: ROC-AUC, Precision, Recall, F1-Score, Geometric Mean

### 5. Model Interpretability
- **SHAP Analysis**: Feature importance and impact visualization
- **Comparative Analysis**: Model performance across different metrics

## ğŸ“Š Results Summary

| Model | Type | ROC-AUC | Key Characteristics |
|-------|------|---------|-------------------|
| Random Forest | Base | **Best** | Robust, interpretable |
| Balanced Random Forest | Base | **Best** | Handles class imbalance well |
| Random Forest | Optimized | Lower | Overfitted to validation set |
| XGBoost | Base/Optimized | Good | Strong gradient boosting |
| SVM | Base/Optimized | Moderate | Less suitable for this dataset |

## ğŸ› ï¸ Key Features

- **Comprehensive Pipeline**: From raw data to model deployment
- **Multiple Algorithms**: Comparative analysis of 4 different ML approaches
- **Class Imbalance Handling**: SMOTE and Balanced algorithms
- **Model Interpretability**: SHAP values for feature importance
- **Reproducible Research**: Well-documented notebook workflow

## ğŸ“ˆ Model Interpretability

The project includes detailed SHAP analysis to understand:
- Most important features for dropout prediction
- Feature impact on individual predictions
- Comparative feature importance across models



## ğŸ“„ License

This project is available for academic and research purposes.


